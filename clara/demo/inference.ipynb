{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fsx/home-knoriy/miniconda3/envs/clasp_2/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import soundfile\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "from clasp import PLCLASP\n",
    "from datamodule.utils import get_log_melspec\n",
    "from text.tokeniser import Tokeniser\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PLCLASP.load_from_checkpoint('/fsx/knoriy/code/CLASP/.models/BAD-perciver-SimTran.ckpt').to(device)\n",
    "tokeniser = Tokeniser()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mel and tokenise text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Set path to audio file\n",
    "########\n",
    "audio_path = './hello_world.mp3'\n",
    "text = [\"hello world\", \"how are you doing today\", \"I am doing great\"]\n",
    "\n",
    "########\n",
    "# Load audio and text\n",
    "########\n",
    "audio, sample_rate = soundfile.read(audio_path)\n",
    "mel = get_log_melspec(audio, sample_rate).permute(1,0).unsqueeze(0)\n",
    "\n",
    "label = pad_sequence([torch.tensor(tokeniser.encode(t, 'en')) for t in text]).T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are you doing today\n"
     ]
    }
   ],
   "source": [
    "model.freeze()\n",
    "with torch.no_grad():\n",
    "    label = label.to(device)\n",
    "    mel = mel.to(device)\n",
    "\n",
    "    ###############\n",
    "    # Audio Features\n",
    "    ###############\n",
    "    audio_features = model.encode_audio(mel)\n",
    "    audio_features = F.normalize(audio_features, dim=-1)\n",
    "    audio_features = model.model.audio_transform(audio_features)\n",
    "\n",
    "    ###############\n",
    "    # Text Features\n",
    "    ###############\n",
    "    text_features = model.encode_text(label)\n",
    "    text_features = F.normalize(text_features, dim=-1)\n",
    "    text_features = model.model.text_transform(text_features)\n",
    "\n",
    "    ###############\n",
    "    # Get Temps\n",
    "    ###############\n",
    "    text_temp, audio_temp = model.get_temps()\n",
    "\n",
    "    ###############\n",
    "    # logits\n",
    "    ###############\n",
    "    logits_per_audio = (audio_temp * (audio_features @ text_features.T))\n",
    "    # logits_per_audio = (audio_temp * (audio_features @ zeroshot_weights.T))\n",
    "\n",
    "    ###############\n",
    "    # Get metrics\n",
    "    ###############\n",
    "    print(text[torch.argmax(logits_per_audio)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clasp_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
